{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#initially checking the accuracy of raw pytesseract for my use and then based on that we will be using pillow and open cv\n",
    "#update: will have to use some preprocessing since colours can effect the reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installations:\n",
    "1) Tesseract for Windows - Github -> Tessearct for Windows by UB Manheim\n",
    "2) pip install pytesseract usin cmd as admin --> tesseract's wrapper for python\n",
    "3) we will be using pytesseracts OCR -> optical character recogonition for the text extraction\n",
    "4) Installed cohere API -pip install cohere -> not using now\n",
    "5) Installed OpenAI API -pip install openai -> not using now\n",
    "6) Installed spacy -pip install spacy -> open source NLP library -> not using now\n",
    "7) installed Google Gen AI package -pip install -q -U google-generativeai\n",
    "8) installed MongoDB for python -pip isntall pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references \n",
    "1) Chat GPT\n",
    "2) https://pypi.org/project/pytesseract/ -> documentation of pytesseract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " Cedric himself knew nothing\n",
      "whatever about it. It had never been\n",
      "even mentioned to him. He knew that\n",
      "his papa had been an Englishman,\n",
      "because his mamma had told him so;\n",
      "but then his papa had died when he\n",
      "was so little a boy that he could not\n",
      "remember very much about him,\n",
      "except that he was big, and had blue\n",
      "eyes and a long mustache, and that it\n",
      "was a splendid thing to be carried\n",
      "around the room on his shoulder.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with some image preprocessing\n",
    "\n",
    "# Configure the path to the Tesseract executable (Windows-specific)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# loading the image using open cv\n",
    "image_path = 'Basic OCR Tests/testocr2.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale (improves OCR accuracy)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Optional: Apply thresholding to improve text visibility\n",
    "#_, threshold_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Convert to PIL Image format (for pytesseract)\n",
    "pil_image = Image.fromarray(gray_image)\n",
    "\n",
    "# running OCR to extract text\n",
    "extracted_text = pytesseract.image_to_string(pil_image)\n",
    "\n",
    "\n",
    "print(\"Extracted Text:\\n\", extracted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy mainly depends on how clear the image is\n",
    "this is just me tyring to implement this idea, i have very minimal knowledge of opencv, pillow and tesseract\n",
    "I am just using the specific functionalitiles of these libraries that I need\n",
    "\n",
    "my plan is to make this thing read some random text and then save it into a database\n",
    "\n",
    "future updates: \n",
    "1) will be to study image processing and then make the reading accuracy better,\n",
    "2) make a webpage where used can upload the image and the read text will go into his database. (mongo db since is nosql and its the only nosql language i know and diff cards will have diff details so using sql there will be many null values or errors)\n",
    "3) try and make that webpage into an app (find collaborators since idk shit abt web dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " This is a lot of 12 point text to test the\n",
      "ocr code and see if it works on all types\n",
      "of file format.\n",
      "\n",
      "The quick brown dog jumped over the\n",
      "lazy fox. The quick brown dog jumped\n",
      "over the lazy fox. The quick brown dog\n",
      "jumped over the lazy fox. The quick\n",
      "brown dog jumped over the lazy fox.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# going to go all out and no do any preprocessing on the images, just RAW image lets see what happens\n",
    "#why im removing all image preprocessing is that, i dont know half the preprocessing that is happening and -\n",
    "#- blatanntly copy paste code from the internet \n",
    "#removed converting to PIL image formate since the ocr function has gotten better over the years\n",
    "\n",
    "\n",
    "\n",
    "# Configure the path to the Tesseract executable (Windows-specific)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# loading the image using open cv\n",
    "image_path = 'Basic OCR Tests/testocr.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale (improves OCR accuracy)\n",
    "#gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Optional: Apply thresholding to improve text visibility\n",
    "#_, threshold_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Convert to PIL Image format (for pytesseract)\n",
    "#pil_image = Image.fromarray(image)\n",
    "\n",
    "# running OCR to extract text\n",
    "extracted_text = pytesseract.image_to_string(image)\n",
    "\n",
    "\n",
    "print(\"Extracted Text:\\n\", extracted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the purpose of this project is to read business cards, we will need to test out some business cards and try to read data\n",
    "1) just randomly read whatever is read as one whole string\n",
    "2) use regex (idk regex, just used once in js lecture) and then try and split it into name, phno, email etc\n",
    "3) if card images are not being read right then apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a lot of 12 point text to test the\n",
      "ocr code and see if it works on all types\n",
      "of file format.\n",
      "\n",
      "The quick brown dog jumped over the\n",
      "lazy fox. The quick brown dog jumped\n",
      "over the lazy fox. The quick brown dog\n",
      "jumped over the lazy fox. The quick\n",
      "brown dog jumped over the lazy fox.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#since not preprocessing im gonna try and completely eliminate using open cv and read the image using pytesseract\n",
    "image=Image.open(\"Basic OCR Tests/testocr.png\")\n",
    "extracted = pytesseract.image_to_string('Basic OCR Tests/testocr.png')\n",
    "print(extracted)\n",
    "#can traslate to diff languages-> refer documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well since that worked we can completely eliminate open cv and pillow since i dont wanna use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to test some business cards since that is our end-goal\n",
    "issues being business card will have different colours, so we will have to use image preporcessing \n",
    "lets upload a random business card image and check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prachi@mail.com\n",
      "\n",
      "PR GH\n",
      "\n",
      "Lower Parel, Mumbai 400033\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing a business card with colour near text to see if we need to do any image preprocessing\n",
    "image=Image.open(\"business cards/bs_card_1.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/bs_card_1.jpg\")\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "her mail is right, but her name is wrong, and address is right, which proves the colour issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAMES SMITH\n",
      "\n",
      "SALES MANAGER\n",
      "\n",
      "& 123 123 123\n",
      "\n",
      "® jamessmith@spc.com\n",
      "\n",
      "pc.com\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing a business card with colour near text to see if we need to do any image preprocessing\n",
    "image=Image.open(\"business cards/bs_card_2.png\")\n",
    "extracted_businesscard=pytesseract.image_to_string(\"business cards/bs_card_2.png\")\n",
    "print(extracted_businesscard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the phone number logo was mistook for an \"&\" symbol and a dot in the mail is missed\n",
    "ignore thr last \"pc.com\" it was covered in the test image itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "©\n",
      "K K OPTICS\n",
      "\n",
      "explore the world of vision\n",
      "\n",
      "multi branded Lenses\n",
      "& quality frames\n",
      "\n",
      "Jetty Road, Vallikavu, Karunagapally - 690 525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#going to try with a business card I found lying around, it has more text and more vibrant colours\n",
    "image=Image.open(\"business cards/bs_card_3.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/bs_card_3.jpg\")\n",
    "\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok that worked well, only the mail wasnt captured, but even i couldnt see it with my eyes\n",
    "1) so this image was taken close up, which means close up image has the best accuracy\n",
    "2) will need image preprocessing, even after image was taken close up, it still had errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@AMRITA\n",
      "\n",
      "VISHWA VIDYAPEETHAM\n",
      "\n",
      "Amritapuri Campus\n",
      "\n",
      "Arun Anilkumar Manjula\n",
      "BCADS\n",
      "\n",
      "School of Computing\n",
      "AM.EN.U3CDS22020\n",
      "\n",
      "2022-2025\n",
      "\n",
      "| 00008\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#going to try out on my uni id card which has so many texts\n",
    "image=Image.open(\"business cards/cld_id_card.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/cld_id_card.jpg\")\n",
    "\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARBE COMPANY\n",
      "\n",
      "BS EVENTS ESTD. 2012\n",
      "SMOKE @ GRILL\n",
      "NALLILA\n",
      "MOB ; 7012352100, 9074212771 -\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#going to try out on my uni id card which has so many texts\n",
    "image=Image.open(\"business cards/barbeque_company_card.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/barbeque_company_card.jpg\")\n",
    "\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARBE COMPANY\n",
      "\n",
      "BS EVENTS ESTD. 2012\n",
      "SMOKE @ GRILL\n",
      "NALLILA\n",
      "MOB ; 7012352100, 9074212771 -\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#going to try out on my uni id card which has so many texts\n",
    "image=Image.open(\"business cards/barbeque_company_card.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/barbeque_company_card.jpg\")\n",
    "\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findings:\n",
    "1) quality of pic and how close up it is\n",
    "2) how clear the text is on the card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION WITHOUT IMAGE  PREPROCESSING : THE CLOSER THE IMAGES ARE CAPTURED THE BETTER THE READING ACCURACY (accuracy is still minimal)\n",
    "\n",
    "HOW GOOD THE TEXT IS ON THE IMAGE (SIZE OF TEXT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update: since its of no use storing the extracted texts directly to database we will be exploring other ways to extract what is what from texts:\n",
    "1) import a NLP model like BERT \n",
    "2) Use openAI api to send the extarcted text to openAI and the AI will seperate it into a JSON format using which we can directly store it to mongoDB --> refer openAI API documentation and the official API page\n",
    "3) Update: cant afford OpenAI API so we will be using a free verstion of Cohere API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cohere\n",
    "# import json\n",
    "\n",
    "# # Initialize Cohere client\n",
    "# co = cohere.Client('cXWKPDfiMOSGZlO9e2xR5bd8l9OghVxJDmpACM1f')  #our cohere free api key\n",
    "\n",
    "# # Predefined examples for classification\n",
    "# examples = [\n",
    "#     #company names\n",
    "#       {\"text\": \"TATA CONSULTANCY SERVICES\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"INFOSYS LIMITED\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"WIPRO TECHNOLOGIES\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"RELIANCE INDUSTRIES\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"HDFC BANK\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"ICICI PRUDENTIAL\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"ADITYA BIRLA GROUP\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"AMUL\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"FLIPKART PRIVATE LIMITED\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"BYJU'S\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"BHARAT PETROLEUM\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"STATE BANK OF INDIA\", \"label\": \"Company Name\"},\n",
    "#     #person names\n",
    "#     {\"text\": \"ARUN KUMAR\", \"label\": \"Name\"},\n",
    "#     {\"text\": \"PRIYA SHARMA\", \"label\": \"Name\"},\n",
    "#     #job titles\n",
    "#     {\"text\": \"SOFTWARE ENGINEER\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"MARKETING EXECUTIVE\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Software Engineer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Project Manager\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Data Scientist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"AI Specialist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Business Analyst\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Graphic Designer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Chartered Accountant\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Operations Manager\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Human Resources Manager\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Product Manager\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Digital Marketing Specialist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Content Writer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Technical Lead\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Civil Engineer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Mechanical Engineer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Electrical Engineer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Marketing Executive\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Chief Executive Officer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Managing Director\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Sales Executive\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Legal Advisor\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Research Scientist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"IT Support Specialist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Professor\", \"label\": \"Job Title\"},\n",
    "#     #phone numbers\n",
    "#     {\"text\": \"+91 9876543210\", \"label\": \"Phone Number\"},\n",
    "#     {\"text\": \"+91 9123456789\", \"label\": \"Phone Number\"},\n",
    "#     #email\n",
    "#     {\"text\": \"arun.kumar@example.in\", \"label\": \"Email\"},\n",
    "#     {\"text\": \"priya.sharma@company.co.in\", \"label\": \"Email\"},\\\n",
    "#     #address\n",
    "#     {\"text\": \"Jetty Road, Vallikavu, Karunagapally - 690525\", \"label\": \"Address\"},\n",
    "#     {\"text\": \"MG Road, Bengaluru, Karnataka - 560001\", \"label\": \"Address\"},\n",
    "#     #idk\n",
    "#     {\"text\": \"www.example.in\", \"label\": \"Website\"},\n",
    "#     {\"text\": \"www.company.co.in\", \"label\": \"Website\"}\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# # Text extracted from a business card  (will add it to a function later on)\n",
    "# text = \"\"\"\n",
    "# K K OPTICS\n",
    "# explore the world of vision\n",
    "# multi branded Lenses\n",
    "# & quality frames\n",
    "# Jetty Road, Vallikavu, Karunagapally - 690 525\n",
    "# \"\"\"\n",
    "\n",
    "# # Split the input text into lines  -> to avoid spaces\n",
    "# lines = text.strip().split(\"\\n\")\n",
    "\n",
    "# # dientifying from our texts\n",
    "# response = co.classify(inputs=lines, examples=examples)\n",
    "\n",
    "# # Structure the output into a JSON-like dictionary\n",
    "# classified_data = {}\n",
    "# for line, classification in zip(lines, response.classifications):\n",
    "#     classified_data[classification.prediction] = line\n",
    "\n",
    "# # Display the structured data\n",
    "# print(\"Classified Data (JSON):\")\n",
    "# print(json.dumps(classified_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE: issues with cohere..it isnt a generative AI, which means it will classify based on examples only, which is difficult\n",
    "1) Varying variety of names in india\n",
    "2) if we need to make example based prediction accurate it will require soo much examples and it wont be worth it\n",
    "3) need GEN AI apis like gpt or claude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update: while searching the pricing for OPEN AI GPT I found this github page\n",
    "- https://github.com/ayaka14732/ChatGPTAPIFree  - Goal to make AI accessible for all but it had stopped due to funding issues\n",
    "- https://github.com/ztjhz/BetterChatGPT - they built a new project on top of that this is a free chat GPT AI, i think u have to run it locally\n",
    "\n",
    "update: running it locally still requires thr paid API keys from open AI\n",
    "I am planning to use ML models- pre trained ofc, specifically Named Entity Recogonition Models (NER) for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we sill be testing out spacy NER without any training i.e in its default form\n",
    "# # python -m spacy download en_core_web_sm  # Download a pre-trained English model\n",
    "\n",
    "# import spacy\n",
    "\n",
    "# # Load SpaCy's pre-trained English model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Input text\n",
    "# text = \"\"\"\n",
    "# ©\n",
    "# K K OPTICS\n",
    "\n",
    "# explore the world of vision\n",
    "\n",
    "# multi branded Lenses\n",
    "# & quality frames\n",
    "\n",
    "# Jetty Road, Vallikavu, Karunagapally - 690 525\n",
    "\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# # Process the text\n",
    "# doc = nlp(text)\n",
    "\n",
    "# # Extract named entities\n",
    "# print(\"Named Entities, their Labels, and Positions:\")\n",
    "# for ent in doc.ents:\n",
    "#     print(f\"{ent.text} ({ent.label_}) [Start: {ent.start}, End: {ent.end}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update: this is trained only for general use and not for specific extratction\n",
    "- I will be going back to generative AI API's\n",
    "\n",
    "update: google cloud API's are there for free trial $300 credit for 90 days, just register with 2 rupees.\n",
    "- got 25,336 rupee worth of credits  -> december 7th to march 9th\n",
    "- planning to use Gemini API\n",
    "- https://ai.google.dev/api?lang=python - Gemini API documentation for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) doesn't work in a single, unified way.  Instead, it encompasses a broad range of techniques and approaches aimed at mimicking human intelligence.  Here's a breakdown of some key concepts:\n",
      "\n",
      "**1. Core Principles:**\n",
      "\n",
      "* **Learning:**  AI systems learn from data.  They identify patterns, relationships, and insights within large datasets. This learning can be:\n",
      "    * **Supervised Learning:** The AI is trained on a labeled dataset (e.g., images of cats labeled \"cat\" and images of dogs labeled \"dog\").  It learns to map inputs to outputs.\n",
      "    * **Unsupervised Learning:** The AI is trained on an unlabeled dataset and tasked with finding structure or patterns on its own (e.g., clustering similar customers based on their purchasing history).\n",
      "    * **Reinforcement Learning:** The AI learns through trial and error, receiving rewards for desired actions and penalties for undesired ones (e.g., training a robot to walk by rewarding it for stable steps and penalizing it for falls).\n",
      "\n",
      "* **Reasoning:**  AI systems can use the learned knowledge to make inferences, draw conclusions, and solve problems. This can involve:\n",
      "    * **Deductive Reasoning:**  Moving from general rules to specific conclusions (e.g., \"All men are mortal; Socrates is a man; therefore, Socrates is mortal\").\n",
      "    * **Inductive Reasoning:** Moving from specific observations to general conclusions (e.g., observing many swans are white and concluding that all swans are white – this can be flawed).\n",
      "    * **Abductive Reasoning:**  Finding the simplest explanation for a set of observations (e.g., seeing footprints in the sand and concluding that someone walked there).\n",
      "\n",
      "* **Self-Correction:**  Many AI systems have mechanisms to adjust their performance based on errors or feedback.  This continuous improvement is crucial for their effectiveness.\n",
      "\n",
      "**2. Key Techniques:**\n",
      "\n",
      "* **Machine Learning (ML):**  A subset of AI focusing on systems that learn from data without explicit programming.  This includes the supervised, unsupervised, and reinforcement learning approaches mentioned above.\n",
      "\n",
      "* **Deep Learning (DL):** A subset of ML that uses artificial neural networks with multiple layers (hence \"deep\") to analyze data.  These networks are particularly effective at processing complex data like images, sound, and text.\n",
      "\n",
      "* **Natural Language Processing (NLP):**  Focuses on enabling computers to understand, interpret, and generate human language.  This is used in chatbots, language translation, and sentiment analysis.\n",
      "\n",
      "* **Computer Vision:**  Enables computers to \"see\" and interpret images and videos.  Applications include object recognition, facial recognition, and medical image analysis.\n",
      "\n",
      "**3. How it Works in Practice (Simplified Example):**\n",
      "\n",
      "Let's say you want to build an AI that identifies cats in images.  A deep learning approach might involve:\n",
      "\n",
      "1. **Data Collection:** Gathering a large dataset of images, some with cats and some without.\n",
      "2. **Training:** Feeding the dataset to a deep neural network. The network learns to identify features that distinguish cats (e.g., pointy ears, whiskers, fur patterns).\n",
      "3. **Testing:** Evaluating the network's performance on a separate set of images it hasn't seen before.\n",
      "4. **Refinement:** Adjusting the network's parameters or architecture based on the testing results to improve accuracy.\n",
      "5. **Deployment:** Using the trained network to identify cats in new images.\n",
      "\n",
      "\n",
      "It's important to note that AI is still an evolving field.  Many challenges remain, including dealing with biased data, ensuring transparency and explainability, and addressing ethical concerns.  The above explanation provides a high-level overview; the specific mechanisms and techniques used vary significantly depending on the application.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"api_key\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worked, now to make it take the text and classify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified Output:\n",
      "Here's a classification of the provided text:\n",
      "\n",
      "1. **Company Name:** BARBE COMPANY, BS EVENTS\n",
      "2. **Tagline (if any):** SMOKE @ GRILL\n",
      "3. **Location:** NALLILA\n",
      "4. **Phone Numbers:** 7012352100, 9074212771\n",
      "5. **Miscellaneous Information:** ESTD. 2012 (Establishment year)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing 1 with business card --> barbeque company\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure API key\n",
    "genai.configure(api_key=\"api_key\")\n",
    "\n",
    "# Define the input text\n",
    "input_text = \"\"\"\n",
    "BARBE COMPANY\n",
    "BS EVENTS ESTD. 2012\n",
    "SMOKE @ GRILL\n",
    "NALLILA\n",
    "MOB ; 7012352100, 9074212771 -\n",
    "\"\"\"\n",
    "\n",
    "# Define a prompt for classification\n",
    "prompt = f\"\"\"\n",
    "Classify the following text into the following categories:\n",
    "1. Company Name\n",
    "2. Tagline (if any)\n",
    "3. Location\n",
    "4. Phone Numbers\n",
    "5. Miscellaneous Information.\n",
    "\n",
    "Input:\n",
    "{input_text}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "# Generate the response\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Print the classified output\n",
    "print(\"Classified Output:\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to get the output in a json format for direct upload to mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified Output:\n",
      "```json\n",
      "{\n",
      "  \"_id\": ObjectId(\"654f917e85327e58a39c6712\"),  // MongoDB automatically generates this\n",
      "  \"companyName\": \"K K OPTICS\",\n",
      "  \"tagline\": \"explore the world of vision\",\n",
      "  \"location\": {\n",
      "    \"address\": \"Jetty Road, Vallikavu, Karunagapally\",\n",
      "    \"pincode\": \"690 525\"\n",
      "  },\n",
      "  \"phoneNumber\": [], //No phone number provided\n",
      "  \"products\": [\"multi branded Lenses\", \"quality frames\"],\n",
      "  \"copyright\": \"©\" \n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing 2 with business card -> kk optics\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure API key\n",
    "genai.configure(api_key=\"api_key\")\n",
    "\n",
    "# Define the input text\n",
    "input_text = \"\"\"\n",
    "©\n",
    "K K OPTICS\n",
    "\n",
    "explore the world of vision\n",
    "\n",
    "multi branded Lenses\n",
    "& quality frames\n",
    "\n",
    "Jetty Road, Vallikavu, Karunagapally - 690 525\n",
    "\"\"\"\n",
    "\n",
    "# Define a prompt for classification\n",
    "prompt = f\"\"\"\n",
    "Classify the following text into the following categories:\n",
    "1. Company Name\n",
    "2. Tagline (if any)\n",
    "3. Location\n",
    "4. Phone Numbers\n",
    "5. Miscellaneous Information.\n",
    "and more based on what you feel the info is about\n",
    "and return it in a format for storing it in a MongoDb database\n",
    "\n",
    "Input:\n",
    "{input_text}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "# Generate the response\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Print the classified output\n",
    "print(\"Classified Output:\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "works well! -> and i havent been charged yet\n",
    "- we will be doing a few more runs tro fine tune our AI response\n",
    "- need to tell it to give us our output in a json format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a test to upload our data to a mongo db server that is hosted locally using MongoDB compass\n",
    "reference - https://www.mongodb.com/docs/languages/python/pymongo-driver/current/write-operations/#std-label-pymongo-write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient  \n",
    "\n",
    "# Connect to local MongoDB instance\n",
    "client = MongoClient(\"mongodb://localhost:27017/\") #our local mongodb server connection key\n",
    "\n",
    "# Access a database\n",
    "db = client[\"business_cards\"]  # our database name\n",
    "\n",
    "# Access a collection\n",
    "collection = db[\"card_details\"]  # oru collection name\n",
    "\n",
    "# Insert a document\n",
    "data ={\n",
    "  \"companyName\": \"K K OPTICS\",\n",
    "  \"tagline\": \"explore the world of vision\",\n",
    "  \"location\": \"Jetty Road, Vallikavu, Karunagapally - 690 525\",\n",
    "  \"phoneNumbers\": [],\n",
    "  \"miscellaneousInformation\": \"multi branded Lenses & quality frames\"\n",
    "}\n",
    "collection.insert_one(data)\n",
    "\n",
    "print(\"Document inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worked! the exmample document is inserted to our database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next objective is to make both the OCR Reading and the Info Classification a function and then use the info of the OCR reading directly into the Classification function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
