{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "#import cohere\n",
    "#import spacy\n",
    "#import io\n",
    "#import sys\n",
    "#from pymongo import MongoClient  \n",
    "\n",
    "\n",
    "\n",
    "#initially checking the accuracy of raw pytesseract for my use and then based on that we will be using pillow and open cv\n",
    "#update: will have to use some preprocessing since colours can effect the reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installations:\n",
    "1) Tesseract for Windows - Github -> Tessearct for Windows by UB Manheim\n",
    "2) pip install pytesseract usin cmd as admin --> tesseract's wrapper for python\n",
    "3) we will be using pytesseracts OCR -> optical character recogonition for the text extraction\n",
    "4) Installed cohere API -pip install cohere -> not using now\n",
    "5) Installed OpenAI API -pip install openai -> not using now\n",
    "6) Installed spacy -pip install spacy -> open source NLP library -> not using now\n",
    "7) installed Google Gen AI package -pip install -q -U google-generativeai\n",
    "8) installed MongoDB for python -pip isntall pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references \n",
    "1) Chat GPT\n",
    "2) https://pypi.org/project/pytesseract/ -> documentation of pytesseract\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    SOME CELLS WILL BE COMMENTED OUT SINCE IT DID ITS WORK, AND I DONT WANT TO REPEAT AND ADD THINGS TO THE DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " Cedric himself knew nothing\n",
      "whatever about it. It had never been\n",
      "even mentioned to him. He knew that\n",
      "his papa had been an Englishman,\n",
      "because his mamma had told him so;\n",
      "but then his papa had died when he\n",
      "was so little a boy that he could not\n",
      "remember very much about him,\n",
      "except that he was big, and had blue\n",
      "eyes and a long mustache, and that it\n",
      "was a splendid thing to be carried\n",
      "around the room on his shoulder.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with some image preprocessing\n",
    "\n",
    "# Configure the path to the Tesseract executable (Windows-specific)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# loading the image using open cv\n",
    "image_path = 'Basic OCR Tests/testocr2.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale (improves OCR accuracy)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Optional: Apply thresholding to improve text visibility\n",
    "#_, threshold_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Convert to PIL Image format (for pytesseract)\n",
    "pil_image = Image.fromarray(gray_image)\n",
    "\n",
    "# running OCR to extract text\n",
    "extracted_text = pytesseract.image_to_string(pil_image)\n",
    "\n",
    "\n",
    "print(\"Extracted Text:\\n\", extracted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy mainly depends on how clear the image is\n",
    "this is just me tyring to implement this idea, i have very minimal knowledge of opencv, pillow and tesseract\n",
    "I am just using the specific functionalitiles of these libraries that I need\n",
    "\n",
    "my plan is to make this thing read some random text and then save it into a database\n",
    "\n",
    "future updates: \n",
    "1) will be to study image processing and then make the reading accuracy better,\n",
    "2) make a webpage where used can upload the image and the read text will go into his database. (mongo db since is nosql and its the only nosql language i know and diff cards will have diff details so using sql there will be many null values or errors)\n",
    "3) try and make that webpage into an app (find collaborators since idk shit abt web dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " This is a lot of 12 point text to test the\n",
      "ocr code and see if it works on all types\n",
      "of file format.\n",
      "\n",
      "The quick brown dog jumped over the\n",
      "lazy fox. The quick brown dog jumped\n",
      "over the lazy fox. The quick brown dog\n",
      "jumped over the lazy fox. The quick\n",
      "brown dog jumped over the lazy fox.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# going to go all out and no do any preprocessing on the images, just RAW image lets see what happens\n",
    "#why im removing all image preprocessing is that, i dont know half the preprocessing that is happening and -\n",
    "#- blatanntly copy paste code from the internet \n",
    "#removed converting to PIL image formate since the ocr function has gotten better over the years\n",
    "\n",
    "\n",
    "\n",
    "# Configure the path to the Tesseract executable (Windows-specific)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# loading the image using open cv\n",
    "image_path = 'Basic OCR Tests/testocr.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale (improves OCR accuracy)\n",
    "#gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Optional: Apply thresholding to improve text visibility\n",
    "#_, threshold_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Convert to PIL Image format (for pytesseract)\n",
    "#pil_image = Image.fromarray(image)\n",
    "\n",
    "# running OCR to extract text\n",
    "extracted_text = pytesseract.image_to_string(image)\n",
    "\n",
    "\n",
    "print(\"Extracted Text:\\n\", extracted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the purpose of this project is to read business cards, we will need to test out some business cards and try to read data\n",
    "1) just randomly read whatever is read as one whole string\n",
    "2) use regex (idk regex, just used once in js lecture) and then try and split it into name, phno, email etc\n",
    "3) if card images are not being read right then apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a lot of 12 point text to test the\n",
      "ocr code and see if it works on all types\n",
      "of file format.\n",
      "\n",
      "The quick brown dog jumped over the\n",
      "lazy fox. The quick brown dog jumped\n",
      "over the lazy fox. The quick brown dog\n",
      "jumped over the lazy fox. The quick\n",
      "brown dog jumped over the lazy fox.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#since not preprocessing im gonna try and completely eliminate using open cv and read the image using pytesseract\n",
    "image=Image.open(\"Basic OCR Tests/testocr.png\")\n",
    "extracted = pytesseract.image_to_string('Basic OCR Tests/testocr.png')\n",
    "print(extracted)\n",
    "#can traslate to diff languages-> refer documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well since that worked we can completely eliminate open cv and pillow since i dont wanna use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to test some business cards since that is our end-goal\n",
    "issues being business card will have different colours, so we will have to use image preporcessing \n",
    "lets upload a random business card image and check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prachi@mail.com\n",
      "\n",
      "PR GH\n",
      "\n",
      "Lower Parel, Mumbai 400033\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing a business card with colour near text to see if we need to do any image preprocessing\n",
    "image=Image.open(\"business cards/bs_card_1.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/bs_card_1.jpg\")\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "her mail is right, but her name is wrong, and address is right, which proves the colour issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAMES SMITH\n",
      "\n",
      "SALES MANAGER\n",
      "\n",
      "& 123 123 123\n",
      "\n",
      "Â® jamessmith@spc.com\n",
      "\n",
      "pc.com\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing a business card with colour near text to see if we need to do any image preprocessing\n",
    "image=Image.open(\"business cards/bs_card_2.png\")\n",
    "extracted_businesscard=pytesseract.image_to_string(\"business cards/bs_card_2.png\")\n",
    "print(extracted_businesscard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the phone number logo was mistook for an \"&\" symbol and a dot in the mail is missed\n",
    "ignore thr last \"pc.com\" it was covered in the test image itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â©\n",
      "K K OPTICS\n",
      "\n",
      "explore the world of vision\n",
      "\n",
      "multi branded Lenses\n",
      "& quality frames\n",
      "\n",
      "Jetty Road, Vallikavu, Karunagapally - 690 525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#going to try with a business card I found lying around, it has more text and more vibrant colours\n",
    "image=Image.open(\"business cards/bs_card_3.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/bs_card_3.jpg\")\n",
    "\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok that worked well, only the mail wasnt captured, but even i couldnt see it with my eyes\n",
    "1) so this image was taken close up, which means close up image has the best accuracy\n",
    "2) will need image preprocessing, even after image was taken close up, it still had errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@AMRITA\n",
      "\n",
      "VISHWA VIDYAPEETHAM\n",
      "\n",
      "Amritapuri Campus\n",
      "\n",
      "Arun Anilkumar Manjula\n",
      "BCADS\n",
      "\n",
      "School of Computing\n",
      "AM.EN.U3CDS22020\n",
      "\n",
      "2022-2025\n",
      "\n",
      "| 00008\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#going to try out on my uni id card which has so many texts\n",
    "image=Image.open(\"business cards/cld_id_card.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/cld_id_card.jpg\")\n",
    "\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARBE COMPANY\n",
      "\n",
      "BS EVENTS ESTD. 2012\n",
      "SMOKE @ GRILL\n",
      "NALLILA\n",
      "MOB ; 7012352100, 9074212771 -\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#going to try out on my uni id card which has so many texts\n",
    "image=Image.open(\"business cards/barbeque_company_card.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/barbeque_company_card.jpg\")\n",
    "\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARBE COMPANY\n",
      "\n",
      "BS EVENTS ESTD. 2012\n",
      "SMOKE @ GRILL\n",
      "NALLILA\n",
      "MOB ; 7012352100, 9074212771 -\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#going to try out on my uni id card which has so many texts\n",
    "image=Image.open(\"business cards/barbeque_company_card.jpg\")\n",
    "extracted=pytesseract.image_to_string(\"business cards/barbeque_company_card.jpg\")\n",
    "\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findings:\n",
    "1) quality of pic and how close up it is\n",
    "2) how clear the text is on the card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION WITHOUT IMAGE  PREPROCESSING : THE CLOSER THE IMAGES ARE CAPTURED THE BETTER THE READING ACCURACY (accuracy is still minimal)\n",
    "\n",
    "HOW GOOD THE TEXT IS ON THE IMAGE (SIZE OF TEXT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update: since its of no use storing the extracted texts directly to database we will be exploring other ways to extract what is what from texts:\n",
    "1) import a NLP model like BERT \n",
    "2) Use openAI api to send the extarcted text to openAI and the AI will seperate it into a JSON format using which we can directly store it to mongoDB --> refer openAI API documentation and the official API page\n",
    "3) Update: cant afford OpenAI API so we will be using a free verstion of Cohere API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Initialize Cohere client\n",
    "# co = cohere.Client('api_key')  #our cohere free api key #wont be on github\n",
    "\n",
    "# # Predefined examples for classification\n",
    "# examples = [\n",
    "#     #company names\n",
    "#       {\"text\": \"TATA CONSULTANCY SERVICES\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"INFOSYS LIMITED\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"WIPRO TECHNOLOGIES\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"RELIANCE INDUSTRIES\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"HDFC BANK\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"ICICI PRUDENTIAL\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"ADITYA BIRLA GROUP\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"AMUL\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"FLIPKART PRIVATE LIMITED\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"BYJU'S\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"BHARAT PETROLEUM\", \"label\": \"Company Name\"},\n",
    "#     {\"text\": \"STATE BANK OF INDIA\", \"label\": \"Company Name\"},\n",
    "#     #person names\n",
    "#     {\"text\": \"ARUN KUMAR\", \"label\": \"Name\"},\n",
    "#     {\"text\": \"PRIYA SHARMA\", \"label\": \"Name\"},\n",
    "#     #job titles\n",
    "#     {\"text\": \"SOFTWARE ENGINEER\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"MARKETING EXECUTIVE\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Software Engineer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Project Manager\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Data Scientist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"AI Specialist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Business Analyst\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Graphic Designer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Chartered Accountant\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Operations Manager\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Human Resources Manager\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Product Manager\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Digital Marketing Specialist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Content Writer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Technical Lead\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Civil Engineer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Mechanical Engineer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Electrical Engineer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Marketing Executive\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Chief Executive Officer\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Managing Director\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Sales Executive\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Legal Advisor\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Research Scientist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"IT Support Specialist\", \"label\": \"Job Title\"},\n",
    "#     {\"text\": \"Professor\", \"label\": \"Job Title\"},\n",
    "#     #phone numbers\n",
    "#     {\"text\": \"+91 9876543210\", \"label\": \"Phone Number\"},\n",
    "#     {\"text\": \"+91 9123456789\", \"label\": \"Phone Number\"},\n",
    "#     #email\n",
    "#     {\"text\": \"arun.kumar@example.in\", \"label\": \"Email\"},\n",
    "#     {\"text\": \"priya.sharma@company.co.in\", \"label\": \"Email\"},\\\n",
    "#     #address\n",
    "#     {\"text\": \"Jetty Road, Vallikavu, Karunagapally - 690525\", \"label\": \"Address\"},\n",
    "#     {\"text\": \"MG Road, Bengaluru, Karnataka - 560001\", \"label\": \"Address\"},\n",
    "#     #idk\n",
    "#     {\"text\": \"www.example.in\", \"label\": \"Website\"},\n",
    "#     {\"text\": \"www.company.co.in\", \"label\": \"Website\"}\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# # Text extracted from a business card  (will add it to a function later on)\n",
    "# text = \"\"\"\n",
    "# K K OPTICS\n",
    "# explore the world of vision\n",
    "# multi branded Lenses\n",
    "# & quality frames\n",
    "# Jetty Road, Vallikavu, Karunagapally - 690 525\n",
    "# \"\"\"\n",
    "\n",
    "# # Split the input text into lines  -> to avoid spaces\n",
    "# lines = text.strip().split(\"\\n\")\n",
    "\n",
    "# # dientifying from our texts\n",
    "# response = co.classify(inputs=lines, examples=examples)\n",
    "\n",
    "# # Structure the output into a JSON-like dictionary\n",
    "# classified_data = {}\n",
    "# for line, classification in zip(lines, response.classifications):\n",
    "#     classified_data[classification.prediction] = line\n",
    "\n",
    "# # Display the structured data\n",
    "# print(\"Classified Data (JSON):\")\n",
    "# print(json.dumps(classified_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE: issues with cohere..it isnt a generative AI, which means it will classify based on examples only, which is difficult\n",
    "1) Varying variety of names in india\n",
    "2) if we need to make example based prediction accurate it will require soo much examples and it wont be worth it\n",
    "3) need GEN AI apis like gpt or claude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update: while searching the pricing for OPEN AI GPT I found this github page\n",
    "- https://github.com/ayaka14732/ChatGPTAPIFree  - Goal to make AI accessible for all but it had stopped due to funding issues\n",
    "- https://github.com/ztjhz/BetterChatGPT - they built a new project on top of that this is a free chat GPT AI, i think u have to run it locally\n",
    "\n",
    "update: running it locally still requires thr paid API keys from open AI\n",
    "I am planning to use ML models- pre trained ofc, specifically Named Entity Recogonition Models (NER) for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we sill be testing out spacy NER without any training i.e in its default form\n",
    "# # python -m spacy download en_core_web_sm  # Download a pre-trained English model\n",
    "\n",
    "\n",
    "\n",
    "# # Load SpaCy's pre-trained English model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Input text\n",
    "# text = \"\"\"\n",
    "# Â©\n",
    "# K K OPTICS\n",
    "\n",
    "# explore the world of vision\n",
    "\n",
    "# multi branded Lenses\n",
    "# & quality frames\n",
    "\n",
    "# Jetty Road, Vallikavu, Karunagapally - 690 525\n",
    "\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# # Process the text\n",
    "# doc = nlp(text)\n",
    "\n",
    "# # Extract named entities\n",
    "# print(\"Named Entities, their Labels, and Positions:\")\n",
    "# for ent in doc.ents:\n",
    "#     print(f\"{ent.text} ({ent.label_}) [Start: {ent.start}, End: {ent.end}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update: this is trained only for general use and not for specific extratction\n",
    "- I will be going back to generative AI API's\n",
    "\n",
    "update: google cloud API's are there for free trial $300 credit for 90 days, just register with 2 rupees.\n",
    "- got 25,336 rupee worth of credits  -> december 7th to march 9th\n",
    "- planning to use Gemini API\n",
    "- https://ai.google.dev/api?lang=python - Gemini API documentation for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aruna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is a broad field encompassing many techniques, but at its core, AI aims to create systems that can perform tasks that typically require human intelligence.  These tasks include things like learning, problem-solving, decision-making, perception, and natural language understanding.  There isn't one single \"how AI works,\" but rather a collection of approaches:\n",
      "\n",
      "**1. Machine Learning (ML):** This is the most prominent approach currently. Instead of being explicitly programmed, ML systems learn from data.  They identify patterns and relationships within the data to make predictions or decisions.  There are several types of ML:\n",
      "\n",
      "* **Supervised Learning:** The algorithm is trained on a labeled dataset, meaning each data point is tagged with the correct answer.  The algorithm learns to map inputs to outputs based on these examples.  Examples include image classification (labeling images as \"cat\" or \"dog\") and spam detection.\n",
      "* **Unsupervised Learning:** The algorithm is trained on an unlabeled dataset.  It aims to discover underlying structures or patterns in the data without explicit guidance.  Examples include clustering (grouping similar data points together) and dimensionality reduction.\n",
      "* **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment.  It receives rewards for desirable actions and penalties for undesirable actions, learning to maximize its cumulative reward.  Examples include game playing (e.g., AlphaGo) and robotics.\n",
      "\n",
      "**2. Deep Learning (DL):** A subfield of ML that uses artificial neural networks with multiple layers (hence \"deep\").  These networks are inspired by the structure and function of the human brain.  Deep learning excels at tasks involving complex patterns and large datasets, such as image recognition, natural language processing, and speech recognition.  Key components include:\n",
      "\n",
      "* **Artificial Neural Networks (ANNs):**  Interconnected nodes (neurons) organized in layers.  Each connection has a weight that determines its influence on the next layer.  The network learns by adjusting these weights based on the data it processes.\n",
      "* **Convolutional Neural Networks (CNNs):**  Specialized for processing grid-like data like images.\n",
      "* **Recurrent Neural Networks (RNNs):**  Designed for sequential data like text and time series.\n",
      "\n",
      "**3. Expert Systems:**  These systems codify the knowledge of human experts in a specific domain.  They use a set of rules and facts to reason and make decisions.  While less prevalent than ML/DL, they are still used in certain niche applications.\n",
      "\n",
      "**4. Search Algorithms:**  Many AI systems rely on sophisticated search algorithms to find optimal solutions to problems. These algorithms explore different possibilities systematically, often using heuristics (rules of thumb) to guide the search.\n",
      "\n",
      "**In essence, AI works by:**\n",
      "\n",
      "1. **Data Collection:** Gathering large amounts of relevant data.\n",
      "2. **Data Preprocessing:** Cleaning, transforming, and preparing the data for use by the AI system.\n",
      "3. **Model Selection:** Choosing the appropriate algorithm (e.g., a specific type of neural network) based on the task and data.\n",
      "4. **Training:** Feeding the data to the chosen algorithm, allowing it to learn patterns and relationships.\n",
      "5. **Evaluation:** Assessing the performance of the trained model using various metrics.\n",
      "6. **Deployment:** Integrating the model into a system or application to perform its intended task.\n",
      "7. **Iteration:** Continuously improving the model by retraining it with new data and adjusting its parameters.\n",
      "\n",
      "It's important to note that AI is constantly evolving.  New techniques and approaches are being developed all the time, pushing the boundaries of what's possible.  While AI systems can be incredibly powerful, it's crucial to understand their limitations and potential biases.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"api_key\") #private key, I wont be putting it on github\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worked, now to make it take the text and classify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified Output:\n",
      "Here's a classification of the provided text:\n",
      "\n",
      "1. **Company Name:** BARBE COMPANY, BS EVENTS\n",
      "\n",
      "2. **Tagline (if any):** SMOKE @ GRILL\n",
      "\n",
      "3. **Location:** NALLILA\n",
      "\n",
      "4. **Phone Numbers:** 7012352100, 9074212771\n",
      "\n",
      "5. **Miscellaneous Information:** ESTD. 2012 (Establishment year)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing 1 with business card --> barbeque company\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure API key\n",
    "genai.configure(api_key=\"api_key\") #private key, I wont be putting it on github\n",
    "\n",
    "# Define the input text\n",
    "input_text = \"\"\"\n",
    "BARBE COMPANY\n",
    "BS EVENTS ESTD. 2012\n",
    "SMOKE @ GRILL\n",
    "NALLILA\n",
    "MOB ; 7012352100, 9074212771 -\n",
    "\"\"\"\n",
    "\n",
    "# Define a prompt for classification\n",
    "prompt = f\"\"\"\n",
    "Classify the following text into the following categories:\n",
    "1. Company Name\n",
    "2. Tagline (if any)\n",
    "3. Location\n",
    "4. Phone Numbers\n",
    "5. Miscellaneous Information.\n",
    "\n",
    "Input:\n",
    "{input_text}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "# Generate the response\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Print the classified output\n",
    "print(\"Classified Output:\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to get the output in a json format for direct upload to mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified Output:\n",
      "```json\n",
      "{\n",
      "  \"companyName\": \"K K OPTICS\",\n",
      "  \"companyDescription\": \"multi branded Lenses & quality frames\",\n",
      "  \"address\": {\n",
      "    \"street\": \"Jetty Road\",\n",
      "    \"locality\": \"Vallikavu\",\n",
      "    \"city\": \"Karunagapally\",\n",
      "    \"postalCode\": \"690 525\"\n",
      "  },\n",
      "  \"website\": null, \n",
      "  \"email\": null,\n",
      "  \"phoneNumbers\": [],\n",
      "  \"personNames\": [],\n",
      "  \"jobTitles\": []\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing 2 with business card -> kk optics\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure API key\n",
    "genai.configure(api_key=\"api_key\") #private key, I wont be putting it on github\n",
    "\n",
    "# Define the input text\n",
    "input_text = \"\"\"\n",
    "Â©\n",
    "K K OPTICS\n",
    "\n",
    "explore the world of vision\n",
    "\n",
    "multi branded Lenses\n",
    "& quality frames\n",
    "\n",
    "Jetty Road, Vallikavu, Karunagapally - 690 525\n",
    "\"\"\"\n",
    "\n",
    "# Define a prompt for classification\n",
    "prompt = prompt =  f\"\"\"\n",
    "Classify the following text into the following categories depending on if you feel like that value is present or not:\n",
    "1. Company Name\n",
    "2. Person Name\n",
    "3. Job Title\n",
    "4. Email\n",
    "5. Location\n",
    "6. Phone Numbers\n",
    "7. Website\n",
    "and more based on what you feel the info is about.\n",
    "\n",
    "and return it in a format for storing it in a MongoDb database\n",
    "\n",
    "Input:\n",
    "    {input_text}\n",
    "\"\"\"\n",
    "\n",
    "# Generate the response\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Print the classified output\n",
    "print(\"Classified Output:\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "works well! -> and i havent been charged yet\n",
    "- we will be doing a few more runs tro fine tune our AI response\n",
    "- need to tell it to give us our output in a json format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a test to upload our data to a mongo db server that is hosted locally using MongoDB compass\n",
    "reference - https://www.mongodb.com/docs/languages/python/pymongo-driver/current/write-operations/#std-label-pymongo-write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Connect to local MongoDB instance\n",
    "client = MongoClient(\"mongodb://localhost:27017/\") #our local mongodb server connection key\n",
    "\n",
    "# Access a database\n",
    "db = client[\"business_cards\"]  # our database name\n",
    "\n",
    "# Access a collection\n",
    "collection = db[\"card_details\"]  # oru collection name\n",
    "\n",
    "# Insert a document\n",
    "data ={\n",
    "  \"Company Name\": \"KK OPTICS\",\n",
    "  \"Location\": \"Jetty Road, Vallikavu, Karunagapally - 690 525\",\n",
    "  \"Description\": \"Multi branded Lenses & quality frames\",\n",
    "  \"Tagline\": \"explore the world of vision\" \n",
    "}\n",
    "collection.insert_one(data)\n",
    "\n",
    "print(\"Document inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worked! the example document is inserted to our database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next objective is to make both the OCR Reading and the Info Classification a function and then use the info of the OCR reading directly into the Classification function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue we will have to work on formatting our json texts since they are being returned as strings\n",
    "I will be working that out here in order to not make the automation file conjested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extract function taken from the functions oage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jordan\\n\\nMitchell\\n\\nCEO\\n\\nVanArsdel, Ltd.\\n\\n5678 Main St. New York, NY 90210\\n212-555-0199\\nwww.vanarsdelltd.com\\n\\nQ@evdanavanarsdetta.com\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function from functions page\n",
    "\n",
    "#function for image extraction\n",
    "def image_extract(image_location):\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' #tesseract path on pc\n",
    "    image=Image.open(image_location)\n",
    "    extracted_businesscard=pytesseract.image_to_string(image)\n",
    "    return extracted_businesscard\n",
    "   # print(extracted_businesscard)\n",
    "    \n",
    "\n",
    "image_extract(\"business cards/microsoft_business_card.png\")\n",
    "#worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for classifying taken from function page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FUNCTION MADE IN FUNCTION PAGE\n",
    "\n",
    "#testing with new promts\n",
    "def classify_text(image_location):\n",
    "    input_text = image_extract(image_location)  # testing 2 with business card -> kk optics\n",
    "\n",
    "    # Configure API key\n",
    "    genai.configure(api_key=\"api_key\")  # private key, I won't be putting it on github\n",
    "\n",
    "    # Define a prompt for classification\n",
    "    prompt =  f\"\"\"\n",
    "Classify the following text into the following categories depending on if you feel like that value is present or not:\n",
    "1. Company Name\n",
    "2. Person Name\n",
    "3. Job Title\n",
    "4. Email\n",
    "5. Location\n",
    "6. Phone Numbers\n",
    "7. Website\n",
    "and more based on what you feel the info is about.\n",
    "and return it in a format for storing it in a MongoDb database\n",
    "if there are null values give it 0 instead of null\n",
    "Input:\n",
    "    {input_text}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # Generate the response\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "   # print(response.text)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nini=classify_text(\"business cards/bs_card_3.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Company Name\": \"KK OPTICS\",\n",
      "  \"Person Name\": 0,\n",
      "  \"Job Title\": 0,\n",
      "  \"Email\": 0,\n",
      "  \"Location\": \"Jetty Road, Vallikavu, Karunagapally - 690 525\",\n",
      "  \"Phone Numbers\": 0,\n",
      "  \"Website\": 0,\n",
      "  \"Products\": \"multi branded Lenses & quality frames\",\n",
      "  \"Description\": \"explore the world of vision\"\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_json_content is a funtion to parse our text as a dict since the AI returns it in str and str cant be uploaded into MongoDB\n",
    "nini=extract_json_content(nini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company Name': 'KK OPTICS', 'Person Name': 0, 'Job Title': 0, 'Email': 0, 'Location': 'Jetty Road, Vallikavu, Karunagapally - 690 525', 'Phone Numbers': 0, 'Website': 0, 'Products': 'multi branded Lenses & quality frames', 'Description': 'explore the world of vision'}\n"
     ]
    }
   ],
   "source": [
    "print(nini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be commenting the below code (adding a text to the database)\n",
    "- it did it's work of taking a variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #trying to put that into the database\n",
    "\n",
    "# # Connect to local MongoDB instance\n",
    "# client = MongoClient(\"mongodb://localhost:27017/\") #our local mongodb server connection key\n",
    "\n",
    "# # Access a database\n",
    "# db = client[\"business_cards\"]  # our database name\n",
    "\n",
    "# # Access a collection\n",
    "# collection = db[\"card_details\"]  # oru collection name\n",
    "\n",
    "# # Insert a document\n",
    "# data =nini\n",
    "# collection.insert_one(data)\n",
    "\n",
    "# print(\"Document inserted successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to add the made by our function to the database\n",
    "REASON: updated the promt to return 0 when null due to MongoDB not reading the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Connect to local MongoDB instance\n",
    "# client = MongoClient(\"mongodb://localhost:27017/\") #our local mongodb server connection key\n",
    "\n",
    "# # Access a database\n",
    "# db = client[\"business_cards\"]  # our database name\n",
    "\n",
    "# # Access a collection\n",
    "# collection = db[\"card_details\"]  # oru collection name\n",
    "\n",
    "# # Insert a document\n",
    "# data ={\n",
    "#   \"Company Name\": \"KK OPTICS\",\n",
    "#   \"Person Name\": 0,\n",
    "#   \"Job Title\": 0,\n",
    "#   \"Email\": 0,\n",
    "#   \"Location\": \"Jetty Road, Vallikavu, Karunagapally - 690 525\",\n",
    "#   \"Phone Numbers\": 0,\n",
    "#   \"Website\": 0,\n",
    "#   \"Industry\": \"Optics\",\n",
    "#   \"Products\": \"Multi branded Lenses & quality frames\" \n",
    "# }\n",
    "# collection.insert_one(data)\n",
    "\n",
    "# print(\"Document inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made the extract_json_content function to parse the AI given text (str) to a (dict) for upload into MongoDB\n",
    "- This was supposed to be done before making the database add function but we faced the parsing issue after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Company Name': 'KK OPTICS',\n",
       " 'Person Name': 0,\n",
       " 'Job Title': 0,\n",
       " 'Email': 0,\n",
       " 'Location': 'Jetty Road, Vallikavu, Karunagapally - 690 525',\n",
       " 'Phone Numbers': 0,\n",
       " 'Website': 0,\n",
       " 'Industry': 'Optics',\n",
       " 'Products': 'Multi branded Lenses & quality frames'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying to remove the ''' json '''' in the generated text\n",
    "\n",
    "\n",
    "def extract_json_content(raw_text):\n",
    "    try:\n",
    "        # Find the first occurrence of '{' and the last occurrence of '}'\n",
    "        start_index = raw_text.find('{')\n",
    "        end_index = raw_text.rfind('}')\n",
    "        \n",
    "        # Extract the JSON content\n",
    "        json_content = raw_text[start_index:end_index + 1]\n",
    "        \n",
    "        # Parse to ensure it's valid JSON\n",
    "        parsed_json = json.loads(json_content)\n",
    "        \n",
    "        # Return the parsed JSON\n",
    "        return parsed_json\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "# Example usage\n",
    "raw_text = \"\"\"\n",
    "'''json\n",
    "{\n",
    "  \"Company Name\": \"KK OPTICS\",\n",
    "  \"Person Name\": 0,\n",
    "  \"Job Title\": 0,\n",
    "  \"Email\": 0,\n",
    "  \"Location\": \"Jetty Road, Vallikavu, Karunagapally - 690 525\",\n",
    "  \"Phone Numbers\": 0,\n",
    "  \"Website\": 0,\n",
    "  \"Industry\": \"Optics\",\n",
    "  \"Products\": \"Multi branded Lenses & quality frames\"\n",
    "}\n",
    "'''\n",
    "\"\"\"\n",
    "\n",
    "extract_json_content(raw_text)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying out io.StringIO from io module to capture the value of the print output since the return function is giving it in the wrong format\n",
    "- update:did not work out, therefore removed the code.\n",
    "- we instead gave the return statement to a variable and then the structure(of output text) did not change, which was our initial problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the json parsing function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Company Name': 'KK OPTICS',\n",
       " 'Person Name': 0,\n",
       " 'Job Title': 0,\n",
       " 'Email': 0,\n",
       " 'Location': 'Jetty Road, Vallikavu, Karunagapally - 690 525',\n",
       " 'Phone Numbers': 0,\n",
       " 'Website': 0,\n",
       " 'Industry': 'Optics',\n",
       " 'Products': 'Multi branded Lenses & quality frames'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_json_content(raw_text)\n",
    "#this can be uploaded to mongo db with our usual upload code, checked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats it for the experiments, In the file:\n",
    "1) We chose our OCR\n",
    "2) We chose how to classify text (NLP or GEN AI)\n",
    "3) We made a functiont to parse the text as a json file\n",
    "4) We chose database (MongoDB) to store our data since diff business cards might have diff info we needed a NoSQL database and I am familiar with MongoDB\n",
    "\n",
    "- The \"functions.ipynb\", is wherer all the functions were made and they were tested out here.\n",
    "- The final output is provided in the file itself, pls do refer it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
